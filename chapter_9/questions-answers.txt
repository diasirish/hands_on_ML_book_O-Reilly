1) Каковы основные преимущества создания вычислительного графа вместо выполнения вычислений напрямую? Каковы главные недостатки?

+ Граф можно разбить на части и прогонять их паралельно на множестве центральных процессоров или графических процессоров. Поэтому мы можем прогонять громадные  нейронные сети на невероятно больших обучающих наборах за приемлемое время. Распределять вычесления по тысячи серверам. (Крупно-масштабируемость) Так-же упрощен само-анализ благодаря TensorBoard. И немало важно библиотека tensorflow может автоматически прогонять градиенты.

- Пошаговая отладка усложнена. Кривая обучения становится более крутой (?)


2) Эквивалентен ли оператор a_val = a.eval(session=sess), оператору a_val = sess.run(a)?

Да


3) Эквивалентен ли оператор a_val, b_val = a.eval(session=sess), b.eval(session=sess), оператору a_val, b_val = sess.run([a,b])?

Нет, первый оператор вызывает и прогоняет граф дважды для каждой переменной, а второй делает это все за раз, для а и б.


4) Можно ли запускать два графа в одном сеансе? 

Кажется что нет. Один сеанс - один граф.


5)  Eсли вы cоздаёте граф g, содержащие переменную w, затем запускайте два потока и открываите в каждом потоке сеанс с применением того же самого g, то будет ли каждый сеанс иметь собственную копию переменной w или она будет разделяться?

Каждый поток будет иметь свою копию переменной w. Это в локальной версии
В распределенной версии - граф будет прогоняться и значения переменных будут лежать в отдельном контейнере, который оба графа будут делить.


6) Когда переменная инициализируется? Когда она уничтожается?

Переменная инициализируется когда мы открываем сеанс, и запускаем вычисление с этой переменной, либо инициализируем ее специальной командой (init = tf.globalvariables_initializer() и sess.run.init(). Уничтожается она при начале сеанса.
В распределенной версии контейнер заполняется переменными, и при истечении сеанса они не удаляются. надо чистить контейнер.


7) В чем разница между заполнителем и переменной?

Заполнитель может занимать место переменной, и при каждом вызове сеанса, в заполнитель можно передать свои переменные. при этом роль заполнителя останется фиксированной в контексте графа в котором мы его создаем. Заполнителей всего лишь содержит в себе информацию о типе форме тензеров, которые представляют, но не имеют значения. Заполнитель и всего лишь содержит себе информацию о типе форме тендеров, которые предоставляют, но не имеют значения. Чтобы вычислить операцию который зависит дополнительно, потребуется предоставить TensorFlow значение этого дополнительно этого заполнителя использо аргумент фит дикт иначе возникает исключения.

Переменная имеет определенное значение после создания она играет свою роль, может быть обновлена, но только в контексте графа, в котором она работает. Переменная поддерживать состояние она сохраняет значение между последовательным прогонами графа, переменной обычно используется для хранения параметров модели, она может применяться для других целей


8) Что случится, когда вы запускаете граф для оценки операции, которые зависит от заполнителя, но не передаёте его значение? Что происходит если операция не зависит от заполнителя.

Первом случае мы получим исключение. Если операция не зависит от заполнителя заполнителя останется пустым.


9) Можно ли при запуске графа передавать выходное значение любой операции или только значение заполнителей?

Да, но не понимаю зачем


10) Как можно установить переменную в любое желаемое значение (во время стадии выполнения)?

С помощью значения feed_dict И созданием функции tf.assing() и placeholder'a нового значения в стадии построения

x_assign.eval(feed_dict={x_new_val: 5.0})


11) 